# RedBus Scraper 

Este mÃ³dulo forma parte del proyecto **GuÃ­a de Viajes EconÃ³micos desde Lima**. Su objetivo es automatizar el proceso de extracciÃ³n de datos de pasajes de la web [RedBus.pe](https://www.redbus.pe) para realizar anÃ¡lisis comparativos de precios, horarios y servicios en rutas interprovinciales de PerÃº.

---

##  CaracterÃ­sticas principales

* ExtracciÃ³n directa desde la **API interna** de RedBus (sin scraping de HTML).
* Manejo de headers, cookies y payload en archivo `config.py`.
* GeneraciÃ³n de carpetas automÃ¡tica por ciudad y mes.
* ValidaciÃ³n de formato de fechas, rango lÃ­mite y bloqueos por exceso de peticiones (HTTP 429).
* Evita duplicados: no vuelve a scrapear fechas que ya tienen un archivo guardado.
* Guardado de resultados en formato JSON crudo.
* ModularizaciÃ³n completa: separaciÃ³n clara entre extracciÃ³n, procesamiento y ejecuciÃ³n.

---

##  Estructura de carpetas

```
scraper/
â”œâ”€â”€ redbus_scraper/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ config.py          # Headers, cookies y body para requests POST
â”‚   â”‚   â””â”€â”€ city_ids.json      # Diccionario ciudad â†’ ID de RedBus
â”‚   â”œâ”€â”€ data/                  # Carpeta base (no contiene los viajes)
â”‚   â”œâ”€â”€ driver/                # Recursos como chromedriver si se usara Selenium
â”‚   â”œâ”€â”€ logs/                  # Logs generados automÃ¡ticamente (futuro)
â”‚   â”œâ”€â”€ screenshots/           # Capturas de Selenium en fase 1 (opcional)
â”‚   â”œâ”€â”€ extractor.py           # FunciÃ³n scrape_redbus() con validaciones robustas
â”‚   â”œâ”€â”€ procesador.py          # Procesamiento modular (JSON â†’ CSV, consola, resumen, etc.)
â”‚   â”œâ”€â”€ main.py                # Fase 1: NavegaciÃ³n automatizada con Selenium
â”‚   â”œâ”€â”€ fase2_runner.py        # Fase 2: Ejecutar mÃºltiples fechas de una ruta
â”‚   â””â”€â”€ runner_general.py      # VersiÃ³n interactiva completa: ciudades + fechas desde consola
```

---

## âš™ï¸ CÃ³digo modularizado y funciones clave

### ğŸ”¹ `scrape_redbus(...)` en `extractor.py`

```python
scrape_redbus(
    from_city_id=195105,
    to_city_id=195256,
    from_name="Lima (Todos)",
    to_name="Trujillo (Todos)",
    date_str="15-Jun-2025",
    output_dir=Path("data/redbus/Trujillo/junio")
)
```

Esta funciÃ³n incluye:

* Manejo de errores HTTP (429, 403)
* ValidaciÃ³n del formato de fecha
* Salto automÃ¡tico si el archivo ya existe
* Delay aleatorio entre peticiones

### ğŸ”¹ `runner_general.py` (interactivo)

* Solicita ciudad origen y destino
* Solicita fechas en formato YYYY-MM-DD
* Valida errores comunes
* Ejecuta scraping en lote solo si es vÃ¡lido

---

## âš¡ Uso rÃ¡pido

```bash
python scraper/redbus_scraper/runner_general.py
```

### Ingresar por consola:

* Ciudad origen (copiar desde city\_ids.json, ej: `Lima (Todos)`)
* Ciudad destino (ej: `Trujillo (Todos)`)
* Fecha inicio: `2025-07-01`
* Fecha fin: `2025-07-31`

El sistema crearÃ¡ automÃ¡ticamente carpetas como:

```
data/redbus/Trujillo/julio/api_response_20250726.json
```

---

##  Flujo de trabajo por fases

| Fase   | DescripciÃ³n                                                              |
| ------ | ------------------------------------------------------------------------ |
| Fase 1 | `main.py`: Prueba con Selenium para observar el comportamiento de RedBus |
| Fase 2 | `fase2_runner.py`: Ejecutar mÃºltiples fechas de una sola ruta            |
| Fase 3 | `runner_general.py`: Ejecutar scraping para fechas y rutas completas     |
| Fase 4 | `procesador.py`: Exportar resultados a consola, CSV o JSON simplificado  |

---

##  Requisitos

Instala las dependencias necesarias desde el archivo `requirements.txt`:

```bash
pip install -r requirements.txt
```

---

##  Pendientes / Siguientes pasos

* Automatizar scraping para mÃºltiples rutas en bucle
* ValidaciÃ³n de precios inusuales o caÃ­das de precio
* Persistencia en base de datos SQLite
* Panel de visualizaciÃ³n de precios histÃ³ricos
* IntegraciÃ³n con otras fuentes: clima, hospedaje, etc.

---

##  Licencia

Este proyecto es de uso acadÃ©mico y educativo. Todos los datos se extraen para fines de anÃ¡lisis no lucrativo.

---
